---
title : "Lec 05: Logistic Regression"
categories :
    - Deep_Learning_Study
tag :
    - [Deep_Learning_Study, Regression]
toc : true
toc_sticky: true
comments: true
sidebar_main: true
use_math: true
---

# 딥러닝 공부 6일차
## Logistic Regression
<br>
<br>

일상속의 많은 문제들중에 두개의 선택지중에 정답을 고르는 문제들 같은 경우가 많습니다.
예를들어 계절학기의 Pass or Non_pass 라던지, 받은 메일이 스팸인지 아닌지 이런식으로 이분법적으로 나누는 경우를 **Binary Classification(이진 분류)** 라고 합니다.

그리고 이러한 이진 분류를 풀기 위한 대표적인 알고리즘이 **Logistic Regression** 입니다.

이 로지스틱 회귀는 이진 분류의 특성 때문에 Regression(회귀)로 사용하지만 Classification(분류)로도 사용이 가능합니다.
<br>
<br>

### Binary Classification

이번 여름방학 계절학기 학생들의 성적으로 패논패를 부여한다고 해봅시다.
50점 이상이면 패스, 50점 아래면 논패스라고 예를 들어보겠습니다.

<p align="center"><img src="/MYPICS/lec05/1.png" width = "200" ></p>

위와 같이 6명의 학생의 점수가 있다고 생각해봅시다. 6명의 학생의 점수중 앞서 말한 것 처럼 패스한 학생을 1 논패스한 학생을 0으로 표햔해보면

<p align="center"><img src="/MYPICS/lec05/2.png" width = "500" ></p>

그 동안 배웠던 가설함수인 직선의 형태로는 위 그림과 같은 모양을 표현하기엔 다소 어려움이 있어보입니다.

그래서 우리는 이번에 새로운 함수를 배우게됩니다.
이번 로지스틱 회귀에서의 가설은 $H(x) = Wx + b$ 가 아니라 $H(x) = f(Wx + b)$ 꼴을 사용하게 됩니다.

위의 그림과 같은 함수를 표현하기위한 함수로 시그모이드함수가 있습니다.
<br>
<br>

### 시그모이드 함수

시그모이드 함수의 원형은 아래와 같습니다. 이제 x대신에 Wx+b 가 대입되면 됩니다.

$$
sigmoid(x) = \frac{1}{1 + e^{-x}}
$$

시그모이드 함수의 그래프를 그려보면 다음과 같습니다. 
<p align="center"><img src="/MYPICS/lec05/3.png" width = "600" ></p>

위 그림이 시그모이드 함수입니다. x가 $-\infty$ 로 향하면 0으로 다가가고, 반대로 $\infty$ 로 향하면 1로 다가가는 함수입니다. 추가로 $f(0)=0.5$ 입니다.

$$
H(x) = sigmoid(Wx + b) = \frac{1}{1 + e^{-(Wx + b)}} = σ(Wx + b)
$$

선형회귀에서는 W가 기울기를 b가 y절편을 의미했다면, 시그모이드함수에서 W 와 b는 함수의 모양과 위치의 차이가 변화합니다.

직접 코드를 쳐보면서 함수가 어떻게 변하는지 확인해봅시다.

* 파이썬에서는 그래프를 그릴 수 있는 도구로서 Matplotlib을 사용할 수 있습니다.
* [Matplotlib 자세한 사용법] 은 여기를 참고해주세요.

[Matplotlib 자세한 사용법]:https://todayisbetterthanyesterday.tistory.com/67

```py
%matplotlib inline
import numpy as np # 넘파이 사용
import matplotlib.pyplot as plt # 맷플롯립사용
```

만약 위의 코드를 주피터 노트북에 실행했더니 오류가 나시는 분들은 matplotlib가 안깔려 있어서 그렇습니다. 그럴 때는 아래 코드를 주피터노트북에서 실행해주세요.
```py
pip install matplotlib
```
설치가 완료되셨으면 직접 코드를 입력하면서 함수의 변화를 관찰하시면 좋을 것 같습니다.

시그모이드 함수를 불러오려면 다음과 같이 코드를 입력하시면 됩니다.
```py
def sigmoid(x): # 시그모이드 함수 정의
    return 1/(1+np.exp(-x))
```
np.exp라고하면 자연상수를 밑으로 가지는 지수함수가 소환이됩니다 그다음 괄호에 들어오는 수 또는 문자가 지수의 역할을 합니다.

```py
x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)

plt.plot(x, y, 'g') # 초록색 선으로 그려라라는 의미
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```
<p align="center"><img src="/MYPICS/lec05/4.png" width = "400" ></p>

위의 그래프 사진과 동일하죠? 그렇다면 잘 소환한 것입니다.
<br>

#### W 값에 따른 경사도 변화

이제 W값을 변화시켰을 때, 함수가 어떻게 변화하는지 알아보겠습니다.

시그모이드 함수로 가설을 사용할때는 $H(x) = f(Wx + b)$ 라고 앞에서 설명드렸습니다.

하지만 여기서는 W 값에따른 변화만을 관찰하기위해서 $f(Wx)$ 즉, 편향을 제외하고 코드를 입력해보았습니다.

```py
x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(0.5*x) # W=0.5
y2 = sigmoid(x) # W=1
y3 = sigmoid(2*x) # W=2

plt.plot(x, y1, 'r--') # W의 값이 0.5일때, 빨간 점선
plt.plot(x, y2, 'g') # W의 값이 1일때, 초록선
plt.plot(x, y3, 'b--') # W의 값이 2일때, 파랑 점선
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```
<p align="center"><img src="/MYPICS/lec05/5.png" width = "400" ></p>

이와같이 가중치 값이 크면 경사가 커지고, 가중치값이 작아지면 경사가 작아지는 것을 확인하실 수 있습니다.

간단히 생각해보면, 극단적으로 시그모이드함수에서 가중치값이 0이라고 생각해보면

$$
Sigmoid(x) = \frac{1}{1+e^{0}} = \frac{1}{2}
$$

즉 $y=0.5$ 인 경사각이 없는 직선이 나온다고 생각해볼 수도 있을 것 같습니다.
