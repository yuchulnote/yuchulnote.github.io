---
title : "Covid Face Mask Webcam Classification : Custom CNN model with numpy(VGG6)"
categories :
    - Deep_Learning_Study
tag :
    - [VGG, Face Mask Detection, CNN]
toc : true
toc_sticky: true 
comments: true
sidebar_main: true
use_math: true
published: true
---

# Covid Face Mask Webcam Classification : Custom CNN model with numpy(VGG6)

넘파이로 직접 구현해서 짜보는 마스크 분류기입니다.
VGG net에 영감을 받아 커스터마이징한 VGG6 모델입니다.
<br>

## 필요한 모듈 import

```py
import numpy as np
import torchvision
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import glob
import sys, os
sys.path.append(os.pardir) # 부모 디렉토리의 파일을 가져올 수 있도록 설정
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from collections import OrderedDict
import pickle
import torch
%matplotlib inline
import cv2
from imutils.video import VideoStream

print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))
device = "cuda" if torch.cuda.is_available() else "CPU"
```

## 디렉토리 설정

```py
from pathlib import Path

folder = "Anaconda/Baram"
project_dir = "MaskClassificaion"

base_path = Path("/Users/yuchul/")
project_path = base_path / folder / project_dir
os.chdir(project_path)
for x in list(project_path.glob("*")):
    if x.is_dir():
        dir_name = str(x.relative_to(project_path))
        os.rename(dir_name, dir_name.split(" ", 1)[0])
print(f"현재 디렉토리 위치: {os.getcwd()}")
```

```py
current_path = Path().absolute()
data_path = current_path / "data"
```

```py
print("현재 디렉토리 위치: {}".format(current_path))
```

```py
if (data_path / "mask_cnn").exists():
    print("이미 'data/mask_cnn' 폴더가 있습니다! 이어서 진행하세요~")
else: print("없습니다")
```

```py
data_dir = './data/mask_cnn'
```

데이터셋의 구성은 다음과 같습니다.

./data/mask_cnn 안에는 Train, Validation, Test 로 폴더가 있고, 그 안에는 Mask, Non_Mask 로 구분되어있습니다.
<br>

## 하이퍼파라미터 설정

```py
batch_size = 32
num_epochs = 30
learning_rate = 0.0001
```
<br>

## Dataset

제가 가진 데이터셋에서 Image.shape[0] 값이 3이 아닌 데이터가 있어서 에러가 났었습니다. (컬러 사진은 R,G,B 3가지를 가지기 때문에 3이여야함)

```py
class MaskNonMaskDataset(Dataset):
    def __init__(self, data_dir, mode=None, transform=None, train_size=None):
        self.old_all_data = sorted(glob.glob(os.path.join(data_dir, mode, '*', '*')))
        
        #RGB 가 아닌 파일필터링
        self.all_data = [i for i in self.old_all_data if transform(Image.open(i)).shape[0] == 3]
    
        self.mode = mode
        self.transform = transform
        self.train_size = train_size
    
    def __getitem__(self, index):
        
        data_path = self.all_data[index]
        img = Image.open(data_path)
        if self.transform != None:
            img = self.transform(img)
        
        if os.path.basename(data_path).startswith("Mask"):
            label = 1
        else:
            label = 0
            
        return img, label 
        # 추후 [1, 0], [0, 1] 로 뒤에서 바꿔주어야함
    
    def __len__(self):
        length = len(self.all_data)
        return length
```

## device 설정

```py
device = 'cuda' if torch.cuda.is_available() else 'cpu'

torch.manual_seed(777)
if device == 'cuda':
    torch.cuda.manual_seed_all(777)
```

## Data Preprocessing

데이터 Augumentaion과 224*224 로 resize 해주었으며, 학습을 시키기 위해 텐서로 변환시켰습니다.

Normalization 같은 경우는 진행하지 않았습니다.(에러때매...)

```py
data_transforms = {
    'train' : transforms.Compose([
        transforms.RandomRotation(5),
        transforms.RandomHorizontalFlip(),
        transforms.RandomResizedCrop(224, scale=(0.96, 1.0), ratio=(0.95, 1.05)),
        transforms.ToTensor(),
        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val' : transforms.Compose([
        transforms.Resize([224, 224]),
        transforms.ToTensor(),
        # transforms.Normalize([0.485,  0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

train_data = MaskNonMaskDataset(data_dir='./data/mask_cnn', mode='Train', transform=data_transforms['train'])
val_data = MaskNonMaskDataset(data_dir='./data/mask_cnn', mode='Validation', transform=data_transforms['val'])
test_data = MaskNonMaskDataset(data_dir='./data/mask_cnn', mode='Test', transform=data_transforms['val'])

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)
```

아래의 두개의 코드로, RGB값을 가지지 않는 파일들이 몇개인지, 그리고 가진 데이터의 개수들을 파악할 수 있습니다.

```py
temp1 = glob.glob(os.path.join(data_dir, "Train", '*', '*'))
temp2 = glob.glob(os.path.join(data_dir, "validation", '*', '*'))
temp3 = glob.glob(os.path.join(data_dir, "test", '*', '*'))
print(len(temp1), len(temp2), len(temp3))
```

```py
print(len(train_data))
print(len(test_data))
print(len(val_data))
x_train = []
t_train = []
```

## 필요한 기능들

### ReLU 함수

```py
class ReLU:
    def __init__(self):
        self.mask = None

    def forward(self, x):
        self.mask = (x <= 0)
        out = x.copy()
        out[self.mask] = 0

        return out

    def backward(self, dout):
        dout[self.mask] = 0
        dx = dout

        return dx
```

### Gradient 구하기(미분)

컴퓨터에서 미분은 사실상 불가하기 때문에, 굉장히 작은 값으로 다루는 차분을 응용하게 됩니다.

미적분 처음 배울 때 보았던 식을 다시보게 되네요!

```py
def get_grad(f, x):
    h = 1e-4 #0.0001
    grad = np.zeros_like(x)
    
    it = np.nditer(x, flag=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]
        x[idx] = float(tmp_val) + h
        fxh1 = f(x) #f(x+h)
        
        x[idx] = tmp_val - h
        fxh2 = f(x) #f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2*h)
        
        x[idx] = tmp_val # 값 복원
        it.iternext()
        
    return grad
```