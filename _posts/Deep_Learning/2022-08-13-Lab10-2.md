---
title : "Lec 10-2: CNN으로 MNIST 분류기 구현하기"
categories :
    - Deep_Learning_Study
tag :
    - [Deep_Learning_Study, Convolution Neural Network]
toc : true
toc_sticky: true 
comments: true
sidebar_main: true
use_math: true
published: true
---

# 딥러닝 공부 19일차, 21일차
<br>
<br>

오늘은 MNIST 손글씨 분류기를 CNN을 통해 구현해보는 시간을 가져보겠습니다.

먼저 필요한 도구들을 import 해줍시다.

```python
import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import torch.nn.init
```

GPU 연산을 위한 설정을 해줍니다.

```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'

torch.manual_seed(777)
if device == 'cuda':
    torch.cuda.manual_seed_all(777)
```


```python
print(device)
```
    cpu



```python
# 하이퍼파라미터

learning_rate = 0.001
training_epochs = 15
batch_size = 100
```


```python
# MNIST datasets

mnist_train = dsets.MNIST(root = 'MNIST_data/',
                         train = True,
                         transform = transforms.ToTensor(),
                         download = True)

mnist_test = dsets.MNIST(root = 'MNIST_data/',
                        train = False,
                        transform = transforms.ToTensor(),
                        download = True)
```

---

훈련데이터와, 테스트데이터셋을 불러옵니다.

`root` 는 저장하는 저장소 위치를 의미합니다.

`train` 은 이 데이터로 학습을 진행할지를 설정해주는 값입니다. 테스트데이터셋은 학습하면 안되므로 false 설정을 해줍니다.

`transform` 함수를 통해 입력값인 이미지 파일을 텐서값으로 변환시켜줍니다.

`download` True를 해주면, `root` 경로에 파일이 없다면 다운받아줘 라는 의미입니다.
<br>

---

```python
data_loader = torch.utils.data.DataLoader

(dataset = mnist_train,
batch_size = batch_size,
shuffle = True,
drop_last = True)
```

---

`data_loader` 파이토치에서는 데이터를 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 `dataset` 과 `dataloader`를 제공합니다.

이를 사용하면 미니배치학습, 데이터셔플, 병렬처리까지 간단히 수행할 수 있습니다.

기본적인 사용방법은 Dataset을 정의하고, 이를 Dataloader에 전달하는 것입니다.

`shuffle` 값을 True로 해주게되면 데이터셋의 순서를 학습하게되는 경우를 방지 할 수 있습니다.

`drop_last` 값을 True로 하게 되면, 총 데이터 개수를 미니배치로 할당한 값으로 나누었을때, 애매하게 남는경우 그 남는 부분을 버리겠다라는 의미입니다.
<br>

----

```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential
        (
            nn.Conv2d(1, 32, Kernel_size = 3, stride = 1, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        self.layer2 = nn.Sequential
        (
            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        self.fc = nn.Linear(7*7*64, 10, bias = True)
        torch.nn.init.xavier_uniform_(self.fc.weight)
        
    def forward(self, x):
        out = self.layer1(x)
        out2 = self.layer2(out)
        
        out3 = out2.view(out2.size(0), -1)
        out4 = self.fc(out3)
        return out
```

```python
model = CNN().to(device)
```

<br>

---

`super().__init__()`

super()로 부모 클래스를 초기화해줌으로써, 부모 클래스의 속성을 sub class가 받아오도록하는 함수입니다.

이것을 사용하지 않으면, 부모 클래스의 속성을 사용할 수 없으므로 학습도 진행이 되지 않습니다! **중요**

`super().__init__() vs super(~~,self).__init__()`

super를 더 명확하게 사용하기 위해서는 단순히 super().__init__()을 하는게 아니라,

**super(파생클래스,self).__init__()** 을 해줍니다. 이와같이 적어주면 기능적으로는 차이가 없지만, 파생클래스와 self를 넣어서 <u>현재 클래스가 어떤 클래스인지 명확하게 표시해줄 수 있는 장점이 있습니다.</u>
<br>

```
out3 = out2.view(out2.size(0), -1)
```

의미를 조금 더 알아보겠습니다. 일단 의미를 파악하기위해 `torch.size()` 에 대해서 조금 더 알아보면

```
torch.size([128, 3, 28, 28])
```

다음과 같은 형태가 있다고보면

128 : mini-batch-size
3 : channel size
28 : img size
28 : img size

다음과 같고, 여기서 0차원 즉 첫번째 차원은 배치사이즈가 됩니다. 그러므로 view 함수에서 -1은 알아서 크기를 조절해달라는 의미이므로, 행의 크기를 배치사이즈로 맞추게되면 1차원 벡터(텐서)로 치환되게 되는 것입니다.

그런 1차원 사이즈로 바꿔야하는 이유는 FC Layer에 들어가야하기 때문입니다.

이러한 과정을 **Flatten** 과정이라고 부릅니다.

---

## 끝! 