---
title : "Deep Learning code 구현을 위한 Q&A"
categories :
    - Deep_Learning_Study
tag :
    - [Deep_Learning_Study, Q&A]
toc : true
toc_sticky: true 
comments: true
sidebar_main: true
use_math: true
published: true
---

# 딥러닝 공부 18일차(+20일차)
<br>
<br>

>그 동안 딥러닝 공부를 하면서 들었던 의문점들을 총 집합해서 공부하고 알아보겠습니다.<br>
>제가 들었던 의문이면 다른 사람들도 똑같이 의문을 가지지 않았을까 싶어 따로 정리해보려합니다.<br>
>도움이 되었으면 좋겠습니다~

## Parameter VS Hiperparameter

파라미터는 한국어로 매개변수입니다. 파라미터는 모델 내부에서 결정되는 변수입니다. 또한 그 값은 데이터로부터 결정됩니다. 

하이퍼 파라미터는 모델링할 때 사용자가 직접 세팅해주는 값을 뜻합니다.
learning rate나 서포트 벡터 머신에서의 C, sigma 값, KNN에서의 K값 등등 굉장히 많습니다.
머신러닝 모델을 쓸 때 사용자가 직접 세팅해야 하는 값은 상당히 많습니다. 

그 모든 게 다 하이퍼 파라미터입니다. 하지만, 많은 사람들이 그런 값들을 조정할 때 그냥 '모델의 파라미터를 조정한다'라는 표현을 씁니다. 원칙적으로는 '모델의 하이퍼 파라미터를 조정한다'라고 해야 합니다.

**파라미터와 하이퍼 파라미터를 구분하는 기준은 사용자가 직접 설정하느냐 아니냐입니다. 사용자가 직접 설정하면 하이퍼 파라미터, 모델 혹은 데이터에 의해 결정되면 파라미터입니다.**
<br>
<br>

## torch.nn.init

torch.nn.init에는 텐서에 초기값을 주기 위해 필요한 함수들이 저장되어 있다.

### torch.nn.init.uniform_(tensor)

<p align="center"><img src="/MYPICS/Deep_Learning/qna/1.png" width = "600" ></p>

x 에 10행 1열 짜리 텐서를 선언해주고, -10 부터 10까지 uniform함수로 행렬의 원소를 무작위로 선언해주는 함수이다.

### torch.nn.init.normal_(tensor)

normal은 정규분포를 의미하며, 앞의 unifrom 함수와 비슷합니다.

<p align="center"><img src="/MYPICS/Deep_Learning/qna/2.png" width = "600" ></p>

평균이 0이고, 표준편차가 200(보통은1로 많이 합니다.)으로 설정해보고 출력해보았습니다.

### torch.nn,init.ones_(tensor)

<p align="center"><img src="/MYPICS/Deep_Learning/qna/3.png" width = "600" ></p>

tensor manipulation 에서 배웠듯이 행렬의 원소들을 1로 채워주는 함수입니다.

### torch.nn.init.zeros_(tensor)

<p align="center"><img src="/MYPICS/Deep_Learning/qna/5.png" width = "600" ></p>

마찬가지로 행렬의 원소들을 0으로 만들어줍니다.

### torch.nn.init.eye_(tensor)

<p align="center"><img src="/MYPICS/Deep_Learning/qna/4.png" width = "600" ></p>

행렬의 대각성분을 1로 만드는 함수입니다.
정방행렬이 아닐경우에는, 그냥 0으로 비워집니다.
<br>
<br>

## Conv1d, 2d, 3d 차이

말 그대로입니다. 1차원 배열 데이터에는 Conv1D를, 2차원 배열 데이터에는 Conv2D를 사용한다. 3차원 배열이면 Conv3D를 사용합니다.

즉, Conv1D, Conv2D, Conv3D 차이는 입력 데이터의 차원이다. 그런데 여기서 끝나면 아쉬우니 코드로 더 살펴봅시다.

필자는 아직 파이토치밖에 공부를 안했는데 찾아본 예시 코드가 텐서플로우입니다... 하지만 이해는 할 수 있으니 갖다 써보겠습니다.

```py
model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
```

위 코드를 보면 입력 차원(input_shape)이 3차원인데 왜 Conv2D지? 라는 의문이 생길 수 있습니다, 또

```py
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),
    tf.keras.layers.Conv1D(128, 5, activation='relu'),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

2번째 줄이랑 3번째 줄만 보명. 입력 차원이 (tokenizer.vocab_size, 64)로 2차원인데 Conv1D를 쓰지....? 라는 의문이 듭니다.

그래서 궁극적으로 **Conv(n)d** 의 차이점은 **합성곱을 진행할 입력 데이터의 차원** 을 의미합니다. 

합성곱 진행 방향을 고려해야 한다는 말입니다.
<br>

### 입력의 형태, 출력의 크기

Convolution의 입력 타입은  Torch.tensor이며 형태는 다음과 같습니다.

$$
input shape : (N \times C \times H \times W)
$$

$$
(batch \text{-} size, channel, height, width)
$$
<br>

이로 인한 출력의 크기는 다음 수식을 통해 구할 수 있다.
<br>

$$
Output size = \frac{입력사이즈-필터사이즈+2\times패딩사이즈}{스트라이드}+1
$$
<br>

### Conv2d

torch.nn.Conv2d(입력채널 수, 출력채널 수, 커널사이즈, 스트라이드, 패딩) 순으로 입력한다고만 알면 거의 막힐일이 없을 것 같습니다.

> **정사각커널 and 상하좌우로 같은 크기만큼 움직이는 패딩**

m = nn.Conv2d(16, 33, 3, stride=2)

한글로 표현하려니 빡세서 아래는 영어로 쓰겠습니다.
<br>

> **non-square kernels and unequal stride and with padding**

m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
<br>

> **non-square kernels and unequal stride and with padding and dilation**

m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))

## 끝!