---
title : "DSP(디지털신호처리) - Sampling & Quantization"
categories :
    - VoiceRecognition
tag :
    - [Deep_Learning, Voice Recognition, Sampling, Quantization]
toc : true
toc_sticky: true 
comments: true
sidebar_main: true
use_math: true
---

# T acdemy_디지털신호처리 기초1
## DSP
자료들은 티아카데미, 도승현 강사님의 자료에서 따왔음을 알립니다.

>현재 인공지능 딥러닝분야에서 이미지 처리쪽은 정말 눈부시게 발전을 해온 반면, 음성쪽은 그렇지가 않았습니다.

>그 이유는 음성데이터에는 많은 잡음들이 있고, 그러한 음성 데이터는 연속적인 아날로그 신호이기 때문에, 이를 컴퓨터가 인식할 수 있게 디지털 신호로 바꾸어 주여야합니다.

>하지만 이렇게 바꿔주는 과정도 만만치 않고, 이를 학습하는 과정도 실제로 쉽지 않다고 알고 있습니다.

<br>
<br>

예제 실습코드도 같이 진행하면서 공부하겠습니다.

```py
!pip install torch
!pip install torchaudio
```

기본 필요파일을 다운로드 받아줍시다.

```py
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
import torchaudio
```

딥러닝 스터디에서 했던 MNIST 데이터셋처럼 오디오 데티어셋을 불러옵니다. 약6기가 정도 되므로 조금 기다려줍시다.

```py
# tra
in_dataset = torchaudio.datasets.LIBRISPEECH("./", url="train-clean-100", download=True) 
test_dataset = torchaudio.datasets.LIBRISPEECH("./", url="test-clean", download=True)
```

```py
test_dataset[0][1]

#소리 데이터, 샘플레이트 
```

<br>
<br>

### Computer가 소리를 인식하는 방식

연속적인 아날로그 신호를 **표본화(Sampling), 양자화(Quantizing), 부호화(Encoding)** 을 거쳐 **디지털 신호(Binary Digital Signal)** 로 변화시켜서 인식하게 됩니다.

>샘플링이란? 1초의 연속적인 시그널을 몇개의 숫자로 표현할 것인가?

**Sampling rate : 얼마나 잘게 쪼갤 것인가?**

잘개 쪼갤수록 원본 데이터와 거이 가까워지기 떄문에 좋지만 Data의 양이 증가하게 됩니다. 만약 너무 크게 쪼개게 된다면, 원본 데이터로 재구성(reconstruct)하기 힘들어 질 것입니다.

<p align="center"><img src="/MYPICS/Voice_Recognition/dsp/1.png" width = "600" ></p>

어떻게 Sampling Rate를 정하나요?

나이키스트-섀넌 표본화 에 따르면 A/D를 거치고, D/A로 복원하기 위해서는 표본화된 신호의 최대 주파수가 두배 보다 더 클 때 가능하다고 합니다.

일반적으로 사용되는 주파수 영역대는 16KHz(speech), 22.05KHz, 44.1KHz(music) 입니다.

>$𝑓𝑠>2𝑓𝑚$  여기서 $𝑓𝑠$는 sampling rate, 그리고 $𝑓𝑚$은 maximum frequency를 말합니다.

위 그림으로 예를 들면 사람의말의 주파수 범위의 최대값이 2000Hz 부근이니까 Sample Rate가 4000Hz 이하로는 내려가면 안되겠다 정도로 파악하면 되겠습니다.