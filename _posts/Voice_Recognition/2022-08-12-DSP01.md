---
title : "DSP(디지털신호처리) - Sampling & Quantization"
categories :
    - VoiceRecognition
tag :
    - [Deep_Learning, Voice Recognition, Sampling, Quantization]
toc : true
toc_sticky: true 
comments: true
sidebar_main: true
use_math: true
---

# T acdemy_디지털신호처리 기초1
## DSP
자료들은 티아카데미, 도승현 강사님의 자료에서 따왔음을 알립니다.

>현재 인공지능 딥러닝분야에서 이미지 처리쪽은 정말 눈부시게 발전을 해온 반면, 음성쪽은 그렇지가 않았습니다.<br>
그 이유는 음성데이터에는 많은 잡음들이 있고, 그러한 음성 데이터는 연속적인 아날로그 신호이기 때문에, 이를 컴퓨터가 인식할 수 있게 디지털 신호로 바꾸어 주여야합니다.<br>
하지만 이렇게 바꿔주는 과정도 만만치 않고, 이를 학습하는 과정도 실제로 쉽지 않다고 알고 있습니다.

<br>
<br>

예제 실습코드도 같이 진행하면서 공부하겠습니다.

```py
!pip install torch
!pip install torchaudio
```

기본 필요파일을 다운로드 받아줍시다.

```py
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
import torchaudio
```

딥러닝 스터디에서 했던 MNIST 데이터셋처럼 오디오 데티어셋을 불러옵니다. 약6기가 정도 되므로 조금 기다려줍시다.

```py
# tra
in_dataset = torchaudio.datasets.LIBRISPEECH("./", url="train-clean-100", download=True) 
test_dataset = torchaudio.datasets.LIBRISPEECH("./", url="test-clean", download=True)
```

<br>
<br>

### Computer가 소리를 인식하는 방식

연속적인 아날로그 신호를 **표본화(Sampling), 양자화(Quantizing), 부호화(Encoding)** 을 거쳐 **디지털 신호(Binary Digital Signal)** 로 변화시켜서 인식하게 됩니다.

>샘플링이란? 1초의 연속적인 시그널을 몇개의 숫자로 표현할 것인가?

**Sampling rate : 얼마나 잘게 쪼갤 것인가?**

잘개 쪼갤수록 원본 데이터와 거이 가까워지기 떄문에 좋지만 Data의 양이 증가하게 됩니다. 만약 너무 크게 쪼개게 된다면, 원본 데이터로 재구성(reconstruct)하기 힘들어 질 것입니다.

<p align="center"><img src="/MYPICS/Voice_Recognition/dsp/1.png" width = "600" ></p>

*어떻게 Sampling Rate를 정하나요?*

나이키스트-섀넌 표본화 에 따르면 A/D를 거치고, D/A로 복원하기 위해서는 표본화된 신호의 최대 주파수가 두배 보다 더 클 때 가능하다고 합니다.

일반적으로 사용되는 주파수 영역대는 16KHz(speech), 22.05KHz, 44.1KHz(music) 입니다.

>$𝑓𝑠>2𝑓𝑚$  여기서 $𝑓𝑠$는 sampling rate, 그리고 $𝑓𝑚$은 maximum frequency를 말합니다.

위 그림으로 예를 들면 사람의말의 주파수 범위의 최대값이 2000Hz 부근이니까 Sample Rate가 4000Hz 이하로는 내려가면 안되겠다 정도로 파악하면 되겠습니다.

---

> 오디오 파일이 다운이 완료된 후, 예시로 아래와 같은 데이터셋을 출력해보면

```py
test_dataset[0]
```
첫번째 데이터를 출력해보면 

>(tensor([[0.0003, 0.0003, 0.0004,  ..., 0.0021, 0.0021, 0.0016]]),
 16000,
 'HE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOUR FATTENED SAUCE',
 1089,
 134686,<br>0)

텐서의 모양이 소리라고 보면 되고, 두번째의 16000이 샘플레이트라고 보면 되겠습니다.
세번째가 실제 말을 적어 놓은 것이고, (뒤에 세가지는 아직 잘 모르겠습니다 ㅠㅠ...)

```py
test_dataset[0][0].shape #소리 데이터, 샘플레이트 
```
위 코드를 출력해보면,

>torch.Size([1, 166960])

이것으로 보아 오디오파일은 3차원텐서느낌이지 않나 생각하였습니다. 왜 느낌이라고 했냐면 실제로 저장된 값이 저 위에 영어나 숫자처럼 모두 숫자로 이루어져있는 것이 아니기 때문입니다.

하지만 이제 그냥 3차원 텐서라고 말하겠습니다. 3차원 텐서이기 때문에 뒤에서 사용할 Librosa 함수에는 위의 166960 같은 값이 대입이 되어야하므로

```py
test_dataset[0][0][0] 
```
과 같은 꼴이 대입이 되어야합니다.

Librosa는 python에서 많이 쓰이는 음성 파일 분석 프로그램입니다.<br>
Librosa를 쓰기 위해선 반드시 ffmpeg의 설치 여부를 확인해야 한다.그렇지 않으면 음성 파일을 로드하는 과정에서 에러가 발생하게 됩니다.

```py
audioData = test_dataset[0][0][0]
sr = test_dataset[0][1]
print(audioData, audioData.shape)
```

>tensor([0.0003, 0.0003, 0.0004,  ..., 0.0021, 0.0021, 0.0016]) torch.Size([166960])

```py
len(audioData)
```

>166960

```py
len(audioData) / sr #duration이 나옴
```

> 음성 전체 길이를 샘플링 데이터로 나누면 duration, 즉 몇초의 사운드인지가 나오게 됩니다.
> 10.435

```py
import IPython.display as ipd
ipd.Audio(audioData, rate=sr)
```
위 코드를 실행하면 
>'HE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOUR FATTENED SAUCE' 를 들으실 수 있습니다.

<br>

#### Resampling

샘플링된 데이터를 다시금 더 높은 sampling rate 혹은 더 낮은 sampling rate로 다시 샘플링할수 있습니다. 이때는 일반적으로 interpolation(보간)을 할때는 low-pass filter를 사용합니다.(Windowed sinc function)
